# Train
epochs: 800
blr: 0.001 # this is base_lr = 1e-4, lr = base_lr * batch_size / 256
warmup_lr: 0.00001 # 1e-56
min_lr: 0.
warmup_epochs: 40
batch_size: 128 # 136 # 256 <---------------------

# Data
data_path: '/kaggle/input/multimae-v1' # Change me

# Wandb logging
log_wandb: True # Set to True to log to Weights & Biases
wandb_project: PretrainSMultiMAE
output_dir: './output/pretrain' # Change directory if needed

gpus:
  - 0
  - 1
